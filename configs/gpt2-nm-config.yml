
# Embeddings
emb: gpt2-nm
context_length: 70
layer_idx: 12

# Embedding modifications: none, rand, emb, shift-emb, concat-emb
emb_mod: none # shift-emb, concat-emb, rand, arb

pca_to: 50
regularization: none # ridge, lasso or none

# Lags
lags: np.arange(-2000,2001,25)
output_dir_name: pca50-ols-lag2k-25-all